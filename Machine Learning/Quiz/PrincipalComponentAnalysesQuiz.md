
# Principal Component Analysis (PCA) Quiz

Here are 50 multiple-choice questions based on the Principal Component Analysis notes.

### Questions

#### Introduction to PCA

1.  **What is the primary goal of Principal Component Analysis (PCA)?**
    *   [ ] A) To increase the number of variables in a dataset.
    *   [ ] B) To simplify complex data by reducing its number of dimensions.
    *   [ ] C) To classify data into different categories.
    *   [ ] D) To predict a continuous value.

    **Answer: B) To simplify complex data by reducing its number of dimensions.**

    **Explanation:**
    *   A is incorrect. PCA is a dimensionality reduction technique, so it aims to decrease, not increase, the number of variables.
    *   B is correct. PCA summarizes a large set of variables into a smaller set of new variables called principal components, thus simplifying the data.
    *   C is incorrect. PCA is an unsupervised dimensionality reduction technique, not a classification algorithm.
    *   D is incorrect. This is the goal of regression analysis, not PCA.

2.  **In the coffee analogy, what does the new variable "Strength" represent?**
    *   [ ] A) One of the original six features of the coffee.
    *   [ ] B) A principal component that captures the combined effect of roast level and bitterness.
    *   [ ] C) A random variable that is unrelated to the coffee's properties.
    *   [ ] D) The average of all six original features.

    **Answer: B) A principal component that captures the combined effect of roast level and bitterness.**

    **Explanation:**
    *   A is incorrect. "Strength" is a new, derived variable, not one of the original ones.
    *   B is correct. Principal components are new variables created by combining the original variables to capture the most significant patterns in the data.
    *   C is incorrect. Principal components are derived directly from the data's variance, not random.
    *   D is incorrect. A principal component is a weighted combination, not a simple average.

3.  **What does the First Principal Component (PC1) always represent?**
    *   [ ] A) The direction in the data with the least amount of variance.
    *   [ ] B) The direction in the data with the most amount of variance.
    *   [ ] C) A direction that is parallel to the original x-axis.
    *   [ ] D) The average of all data points.

    **Answer: B) The direction in the data with the most amount of variance.**

    **Explanation:**
    *   A is incorrect. PCA prioritizes directions with the most variance, as this is where the most information is.
    *   B is correct. PC1 is defined as the axis that captures the maximum variance in the dataset, making it the most important summary direction.
    *   C is incorrect. The direction of PC1 is determined by the data's structure, not the original axes.
    *   D is incorrect. The average is a single point, not a direction.

4.  **Which of the following is a primary reason to use PCA?**
    *   [ ] A) To make a dataset more complex.
    *   [ ] B) To visualize high-dimensional data in 2D or 3D.
    *   [ ] C) To add noise to the data.
    *   [ ] D) To ensure all variables have the same mean.

    **Answer: B) To visualize high-dimensional data in 2D or 3D.**

    **Explanation:**
    *   A is incorrect. The goal of PCA is simplification.
    *   B is correct. By reducing a dataset with many variables down to 2 or 3 principal components, PCA allows for the creation of scatter plots that can reveal patterns, clusters, or outliers.
    *   C is incorrect. PCA is often used for noise reduction, not addition.
    *   D is incorrect. Standardization, a pre-processing step for PCA, ensures variables have a mean of 0, but this is not the goal of PCA itself.

5.  **How does PCA help in noise reduction?**
    *   [ ] A) By adding new, random features.
    *   [ ] B) By focusing on the components with the most variance and filtering out later components which often capture noise.
    *   [ ] C) By removing all data points that are considered outliers.
    *   [ ] D) By increasing the dimensionality of the data.

    **Answer: B) By focusing on the components with the most variance and filtering out later components which often capture noise.**

    **Explanation:**
    *   A is incorrect. PCA does not add random features.
    *   B is correct. The assumption is that the most important information is in the directions of highest variance (the first few PCs), while noise resides in the directions of lowest variance (the last few PCs). By discarding the later PCs, we can filter out noise.
    *   C is incorrect. PCA does not inherently remove outliers, although it can help in identifying them.
    *   D is incorrect. This is the opposite of what PCA does.

6.  **The principal components generated by PCA are:**
    *   [ ] A) Always correlated with each other.
    *   [ ] B) Always uncorrelated with each other.
    *   [ ] C) The same as the original variables.
    *   [ ] D) Always equal in number to the original variables.

    **Answer: B) Always uncorrelated with each other.**

    **Explanation:**
    *   A is incorrect. A key property of PCA is that the principal components are orthogonal, which means they are uncorrelated.
    *   B is correct. Each principal component is constructed to be orthogonal to the previous ones, ensuring that the new variables are statistically independent and not redundant.
    *   C is incorrect. They are new variables derived from the original ones.
    *   D is incorrect. While you can compute as many PCs as there are original variables, the goal of dimensionality reduction is to use fewer PCs than original variables.

7.  **What is the "curse of dimensionality"?**
    *   [ ] A) The problem where models perform better with more dimensions.
    *   [ ] B) The problem where models perform poorly in high-dimensional space because the data becomes sparse.
    *   [ ] C) The difficulty of visualizing data in more than three dimensions.
    *   [ ] D) The fact that dimensionality can only be reduced, not increased.

    **Answer: B) The problem where models perform poorly in high-dimensional space because the data becomes sparse.**

    **Explanation:**
    *   A is incorrect. The curse of dimensionality describes a performance degradation.
    *   B is correct. When the number of features is very high compared to the number of data points, the feature space becomes vast and empty. This makes it difficult for models to find meaningful patterns, leading to overfitting and poor generalization.
    *   C is a consequence of high dimensionality, but not the "curse" itself in the machine learning context.
    *   D is incorrect. Dimensionality can be increased, for example, through feature engineering.

8.  **In the book summary analogy, what is lost when performing PCA?**
    *   [ ] A) The main plot and characters.
    *   [ ] B) Some of the minor details.
    *   [ ] C) The author's name.
    *   [ ] D) The page numbers.

    **Answer: B) Some of the minor details.**

    **Explanation:**
    *   A is incorrect. PCA aims to keep the most important information (the main plot).
    *   B is correct. Dimensionality reduction is a trade-off. By summarizing the data, we inevitably lose some of the less important information, which corresponds to the later principal components with low variance.
    *   C and D are incorrect as they are not part of the core information PCA tries to preserve.

9.  **PCA is a technique for:**
    *   [ ] A) Supervised learning
    *   [ ] B) Unsupervised learning
    *   [ ] C) Reinforcement learning
    *   [ ] D) Semi-supervised learning

    **Answer: B) Unsupervised learning**

    **Explanation:**
    *   PCA does not use any labels or target variables to find the principal components. It only looks at the structure (variance) of the input features, making it an unsupervised method.

10. **After applying PCA, the new variables are called:**
    *   [ ] A) Eigenvalues
    *   [ ] B) Eigenvectors
    *   [ ] C) Principal Components
    *   [ ] D) Standardized Variables

    **Answer: C) Principal Components**

    **Explanation:**
    *   A and B are incorrect. Eigenvalues and eigenvectors are used in the calculation of PCA, but they are not the final transformed variables.
    *   C is correct. The new, summary variables created by PCA are called principal components.
    *   D is incorrect. Standardization is a preprocessing step, not the output of PCA.

#### Correlation and Covariance

11. **What does a Pearson correlation coefficient of -1 indicate?**
    *   [ ] A) A perfect positive correlation.
    *   [ ] B) No correlation.
    *   [ ] C) A perfect negative correlation.
    *   [ ] D) A weak negative correlation.

    **Answer: C) A perfect negative correlation.**

    **Explanation:**
    *   A is incorrect. A value of +1 indicates a perfect positive correlation.
    *   B is incorrect. A value of 0 indicates no correlation.
    *   C is correct. A value of -1 means that as one feature increases, the other decreases by a proportional amount.
    *   D is incorrect. -1 is the strongest possible negative correlation.

12. **What is the main purpose of standardization before calculating correlation?**
    *   [ ] A) To make the covariance value easier to interpret by scaling it to a range of -1 to +1.
    *   [ ] B) To remove all negative values from the data.
    *   [ ] C) To ensure the covariance is always a positive number.
    *   [ ] D) To increase the magnitude of the covariance.

    **Answer: A) To make the covariance value easier to interpret by scaling it to a range of -1 to +1.**

    **Explanation:**
    *   A is correct. Covariance values are unbounded, making them hard to compare. Dividing the covariance by the standard deviations of the features (standardization) scales the result to the consistent and interpretable range of the correlation coefficient.
    *   B, C, and D are incorrect. Standardization does not achieve these things.

13. **In the ice cream sales example, why was the covariance a positive number (112.5)?**
    *   [ ] A) Because the temperature was always positive.
    *   [ ] B) Because days with below-average temperature also had below-average sales, and vice-versa.
    *   [ ] C) Because the number of sales was always higher than the temperature.
    *   [ ] D) Because the sample size was small.

    **Answer: B) Because days with below-average temperature also had below-average sales, and vice-versa.**

    **Explanation:**
    *   A is incorrect. The sign of the data values does not determine the sign of the covariance.
    *   B is correct. Covariance is positive when the two features tend to be on the same side of their respective averages at the same time (both above or both below). This indicates they move in the same direction.
    *   C is incorrect. The relative magnitudes of the features do not determine the sign of the covariance.
    *   D is incorrect. The sample size affects the value, but not necessarily its sign.

14. **What is covariance?**
    *   [ ] A) A measure of how much two variables change together, scaled to a range of -1 to +1.
    *   [ ] B) A measure of how spread out a single variable is.
    *   [ ] C) A measure of whether two variables tend to move in the same or opposite directions.
    *   [ ] D) The average value of a single variable.

    **Answer: C) A measure of whether two variables tend to move in the same or opposite directions.**

    **Explanation:**
    *   A describes correlation, which is standardized covariance.
    *   B describes variance or standard deviation.
    *   C is correct. Covariance is a measure of the joint variability of two random variables. Its sign indicates the direction of the linear relationship.
    *   D describes the mean.

15. **If the correlation between two features is 0, it means:**
    *   [ ] A) The two features are identical.
    *   [ ] B) There is no linear relationship between the features.
    *   [ ] C) As one feature increases, the other decreases.
    *   [ ] D) The two features have a strong non-linear relationship.

    **Answer: B) There is no linear relationship between the features.**

    **Explanation:**
    *   A would result in a correlation of +1.
    *   B is correct. A correlation of 0 indicates that there is no predictable linear pattern between the two variables. It does not rule out a non-linear relationship.
    *   C would result in a negative correlation.
    *   D is possible, but a correlation of 0 does not guarantee it.

16. **The formula for correlation involves dividing the covariance by:**
    *   [ ] A) The sample size.
    *   [ ] B) The mean of each feature.
    *   [ ] C) The product of the standard deviations of each feature.
    *   [ ] D) The sum of the variances of each feature.

    **Answer: C) The product of the standard deviations of each feature.**

    **Explanation:**
    *   The formula is: Correlation = Covariance / (StdDev(X) * StdDev(Y)). This step standardizes the covariance.

17. **In the context of PCA, a covariance matrix is computed to:**
    *   [ ] A) Understand the relationships and redundancies between the variables.
    *   [ ] B) Find the average value of each variable.
    *   [ ] C) Standardize the data.
    *   [ ] D) Classify the data points.

    **Answer: A) Understand the relationships and redundancies between the variables.**

    **Explanation:**
    *   A is correct. The covariance matrix is the foundation of PCA. It contains the variance of each variable (on the diagonal) and the covariance between each pair of variables (off-diagonal), which together describe the shape and structure of the data.
    *   B is calculated during the standardization step, before the covariance matrix.
    *   C is a pre-processing step.
    *   D is not the purpose of the covariance matrix.

18. **If two variables are perfectly correlated (+1 or -1), what does this imply for PCA?**
    *   [ ] A) PCA cannot be performed.
    *   [ ] B) The two variables provide redundant information, and PCA will be very effective at reducing dimensionality.
    *   [ ] C) The two variables are completely independent.
    *   [ ] D) The first principal component will have an eigenvalue of 0.

    **Answer: B) The two variables provide redundant information, and PCA will be very effective at reducing dimensionality.**

    **Explanation:**
    *   A is incorrect. PCA is ideal for this situation.
    *   B is correct. If two variables are perfectly correlated, they are essentially measuring the same underlying property. PCA will create a first principal component that captures this shared information, and the second principal component will have zero variance, allowing for a perfect reduction of one dimension with no loss of information.
    *   C is the opposite of what perfect correlation means.
    *   D is incorrect. The first PC will have a large eigenvalue, while the second PC will have an eigenvalue of 0.

19. **The diagonal of a covariance matrix contains the:**
    *   [ ] A) Covariances
    *   [ ] B) Correlations
    *   [ ] C) Variances
    *   [ ] D) Means

    **Answer: C) Variances**

    **Explanation:**
    *   The element at row i, column i of a covariance matrix is the covariance of variable i with itself, which is its variance.

20. **Why is it important to standardize data before performing PCA?**
    *   [ ] A) Because PCA cannot handle negative numbers.
    *   [ ] B) To prevent variables with larger scales from dominating the analysis.
    *   [ ] C) To ensure all eigenvalues are positive.
    *   [ ] D) To make the data fit a normal distribution.

    **Answer: B) To prevent variables with larger scales from dominating the analysis.**

    **Explanation:**
    *   A is incorrect. PCA can handle negative numbers.
    *   B is correct. PCA is a variance-based technique. If one variable has a much larger range (and thus variance) than others, it will disproportionately influence the principal components. Standardization gives all variables equal weight.
    *   C is incorrect. Eigenvalues of a covariance matrix are always non-negative, regardless of standardization.
    *   D is incorrect. Standardization does not change the shape of the distribution.

#### Projection and Change of Axis

21. **In the context of PCA, what is a "projection"?**
    *   [ ] A) The process of adding new dimensions to the data.
    *   [ ] B) The process of mapping data points onto the new principal component axes.
    *   [ ] C) The process of calculating the mean of the data.
    *   [ ] D) The process of selecting a random subset of the data.

    **Answer: B) The process of mapping data points onto the new principal component axes.**

    **Explanation:**
    *   A is the opposite of what projection achieves in PCA.
    *   B is correct. After finding the principal components (the new axes), the original data is projected onto them. The coordinates of these projections are the new values in the reduced-dimensional space.
    *   C and D are unrelated to the concept of projection in this context.

22. **What is the main goal of a "change of axis" in PCA?**
    *   [ ] A) To rotate the coordinate system to be better aligned with the data's variance.
    *   [ ] B) To shift the data so that its mean is at (0,0).
    *   [ ] C) To randomly shuffle the data points.
    *   [ ] D) To convert all data to positive values.

    **Answer: A) To rotate the coordinate system to be better aligned with the data's variance.**

    **Explanation:**
    *   A is correct. PCA finds a new set of axes (the principal components) that are aligned with the directions of maximum spread in the data. This change of axis simplifies the data's structure.
    *   B is achieved by mean-centering the data during standardization, which happens before the change of axis.
    *   C and D are incorrect.

23. **In the Manhattan map analogy, what does the "Broadway" axis (B-axis) represent?**
    *   [ ] A) The original North-South axis.
    *   [ ] B) A randomly chosen direction.
    *   [ ] C) The First Principal Component (PC1).
    *   [ ] D) The average location of all cafes.

    **Answer: C) The First Principal Component (PC1).**

    **Explanation:**
    *   Broadway represents the direction along which the cafes (data points) are most spread out. This is conceptually identical to the First Principal Component, which is the axis of maximum variance.

24. **Projecting a vector v onto another vector u gives you:**
    *   [ ] A) The component of v that is perpendicular to u.
    *   [ ] B) The component of v that points in the same direction as u.
    *   [ ] C) A vector that is longer than both v and u.
    *   [ ] D) The angle between v and u.

    **Answer: B) The component of v that points in the same direction as u.**

    **Explanation:**
    *   A describes the rejection, or the part of v that is orthogonal to u.
    *   B is correct. The projection of v onto u is the "shadow" of v on the line defined by u, representing how much of v lies in the direction of u.
    *   C is incorrect. The projection's length is at most the length of v.
    *   D is incorrect. The dot product is related to the angle, but the projection is a vector.

25. **After changing the axes in PCA, the new axes are:**
    *   [ ] A) The original x and y axes.
    *   [ ] B) The principal components.
    *   [ ] C) Randomly generated lines.
    *   [ ] D) Always parallel to the original axes.

    **Answer: B) The principal components.**

    **Explanation:**
    *   The principal components (which are the eigenvectors of the covariance matrix) form the new set of axes for the data.

26. **The "shadow" analogy for projection helps to understand:**
    *   [ ] A) How a higher-dimensional object can be represented in a lower-dimensional space.
    *   [ ] B) Why data needs to be standardized.
    *   [ ] C) How to calculate the mean of a dataset.
    *   [ ] D) Why eigenvectors are always orthogonal.

    **Answer: A) How a higher-dimensional object can be represented in a lower-dimensional space.**

    **Explanation:**
    *   A is correct. The shadow (a 2D representation) of a 3D object is a perfect analogy for projection, where a data point from a high-dimensional space is mapped onto a lower-dimensional subspace (the new axes).

27. **In PCA, projecting the data onto the principal components results in:**
    *   [ ] A) The original data, unchanged.
    *   [ ] B) The new coordinates of the data in the reduced-dimensional space.
    *   [ ] C) The eigenvalues of the covariance matrix.
    *   [ ] D) A set of labels for the data.

    **Answer: B) The new coordinates of the data in the reduced-dimensional space.**

    **Explanation:**
    *   The result of the projection is a new set of values for each data point. These values are the coordinates along the new principal component axes.

28. **Why is the projection onto the first few principal components a "meaningful summary"?**
    *   [ ] A) Because it contains all the original variables.
    *   [ ] B) Because these components capture the most variance and thus the most information.
    *   [ ] C) Because it makes the data perfectly fit a straight line.
    *   [ ] D) Because it is the most complex representation of the data.

    **Answer: B) Because these components capture the most variance and thus the most information.**

    **Explanation:**
    *   By definition, the first few PCs are the directions where the data is most spread out. This spread represents information, so projecting onto these axes preserves the most important patterns in the data.

29. **The change of axis in PCA is determined by:**
    *   [ ] A) The user's preference.
    *   [ ] B) The number of data points.
    *   [ ] C) The structure and variance of the data itself.
    *   [ ] D) A random process.

    **Answer: C) The structure and variance of the data itself.**

    **Explanation:**
    *   The new axes (principal components) are the eigenvectors of the data's covariance matrix. Their directions are therefore dictated entirely by the internal structure and patterns of variance within the data.

30. **Projecting a 10-dimensional dataset onto its first two principal components allows you to:**
    *   [ ] A) Keep all 10 original dimensions.
    *   [ ] B) Visualize the data in a 2D scatter plot.
    *   [ ] C) Increase the accuracy of any model to 100%.
    *   [ ] D) Understand the variance of all 10 original dimensions perfectly.

    **Answer: B) Visualize the data in a 2D scatter plot.**

    **Explanation:**
    *   By reducing the data to two dimensions (PC1 and PC2), you can plot the new coordinates on a standard 2D graph to look for patterns, which would be impossible with the original 10 dimensions.

#### Orthogonality and Eigenvectors

31. **What does it mean for two vectors to be "orthogonal"?**
    *   [ ] A) They are parallel to each other.
    *   [ ] B) They have the same length.
    *   [ ] C) They are perpendicular to each other (meet at a 90-degree angle).
    *   [ ] D) They point in the same direction.

    **Answer: C) They are perpendicular to each other (meet at a 90-degree angle).**

    **Explanation:**
    *   Orthogonal is the mathematical term for perpendicular.

32. **Why is it important that principal components are orthogonal?**
    *   [ ] A) It ensures they are correlated and provide redundant information.
    *   [ ] B) It ensures they are uncorrelated and provide unique, non-redundant information.
    *   [ ] C) It makes them harder to interpret.
    *   [ ] D) It ensures they all have the same length.

    **Answer: B) It ensures they are uncorrelated and provide unique, non-redundant information.**

    **Explanation:**
    *   Orthogonality means the new axes are independent. The information captured by PC2 is completely different from the information captured by PC1, making the new feature set efficient and free of redundancy.

33. **What is an eigenvector of a matrix?**
    *   [ ] A) A vector that, when transformed by the matrix, changes its direction randomly.
    *   [ ] B) A vector that, when transformed by the matrix, does not change its direction, only its length.
    *   [ ] C) A vector that is always equal to the zero vector.
    *   [ ] D) The inverse of the matrix.

    **Answer: B) A vector that, when transformed by the matrix, does not change its direction, only its length.**

    **Explanation:**
    *   An eigenvector represents a characteristic direction for the matrix transformation. When the matrix is applied, the eigenvector is simply scaled (stretched or shrunk) by its corresponding eigenvalue.

34. **What is an eigenvalue?**
    *   [ ] A) The direction of an eigenvector.
    *   [ ] B) The scalar factor by which an eigenvector is scaled when transformed by the matrix.
    *   [ ] C) The angle between two eigenvectors.
    *   [ ] D) The length of an eigenvector.

    **Answer: B) The scalar factor by which an eigenvector is scaled when transformed by the matrix.**

    **Explanation:**
    *   The eigenvalue (λ) in the equation Av = λv represents the amount of "stretch" or "shrink" applied to the eigenvector v.

35. **In PCA, the eigenvectors of which matrix become the principal components?**
    *   [ ] A) The original data matrix.
    *   [ ] B) The standardized data matrix.
    *   [ ] C) The covariance matrix.
    *   [ ] D) The identity matrix.

    **Answer: C) The covariance matrix.**

    **Explanation:**
    *   The core of PCA is the eigendecomposition of the covariance matrix. The eigenvectors of the covariance matrix give the directions of maximum variance, which are the principal components.

36. **In PCA, what do the eigenvalues represent?**
    *   [ ] A) The direction of the principal components.
    *   [ ] B) The amount of variance captured by each principal component.
    *   [ ] C) The mean of the data along each principal component.
    *   [ ] D) The number of original variables.

    **Answer: B) The amount of variance captured by each principal component.**

    **Explanation:**
    *   The eigenvalue associated with an eigenvector (a principal component) is a measure of how much of the total data variance lies along that principal component's direction. Larger eigenvalues correspond to more important PCs.

37. **A symmetric matrix is a square matrix that is equal to its:**
    *   [ ] A) Inverse
    *   [ ] B) Determinant
    *   [ ] C) Transpose
    *   [ ] D) Eigenvector

    **Answer: C) Transpose**

    **Explanation:**
    *   A symmetric matrix is defined by the property A = Aᵀ, meaning if you flip it across its main diagonal, it remains unchanged.

38. **What is the special property of eigenvectors for symmetric matrices?**
    *   [ ] A) They are always parallel to each other.
    *   [ ] B) They are always orthogonal to each other.
    *   [ ] C) They always have a length of 1.
    *   [ ] D) They are always equal to the original axes.

    **Answer: B) They are always orthogonal to each other.**

    **Explanation:**
    *   A key theorem in linear algebra states that the eigenvectors of a symmetric matrix corresponding to distinct eigenvalues are orthogonal. This property is fundamental to why PCA works.

39. **Why is it significant that the covariance matrix is always symmetric?**
    *   [ ] A) It means the covariance matrix is easy to invert.
    *   [ ] B) It guarantees that its eigenvectors will be orthogonal, providing a valid basis for the new coordinate system.
    *   [ ] C) It means all the variances are equal.
    *   [ ] D) It means the data has no correlation.

    **Answer: B) It guarantees that its eigenvectors will be orthogonal, providing a valid basis for the new coordinate system.**

    **Explanation:**
    *   The symmetry of the covariance matrix is crucial. Because it is symmetric, its eigenvectors are guaranteed to be orthogonal. This allows them to form a new, non-redundant coordinate system (the principal components) for the data.

40. **The equation Av = λv defines the relationship between:**
    *   [ ] A) A matrix A, its projection v, and its dimension λ.
    *   [ ] B) A matrix A, its eigenvector v, and its eigenvalue λ.
    *   [ ] C) A vector A, its direction v, and its length λ.
    *   [ ] D) A matrix A, its transpose v, and its determinant λ.

    **Answer: B) A matrix A, its eigenvector v, and its eigenvalue λ.**

    **Explanation:**
    *   This is the fundamental equation defining eigenvectors and eigenvalues. It states that applying the transformation A to the vector v results in the same vector scaled by λ.

#### The 5 Steps of PCA

41. **What is the first step in the PCA algorithm?**
    *   [ ] A) Compute the covariance matrix.
    *   [ ] B) Standardize the data.
    *   [ ] C) Compute eigenvectors and eigenvalues.
    *   [ ] D) Project the data onto the new axes.

    **Answer: B) Standardize the data.**

    **Explanation:**
    *   Before any other calculations, the data must be standardized (rescaled to have a mean of 0 and a standard deviation of 1) to ensure that variables with different scales are treated equally.

42. **After standardizing the data, what is the next step in PCA?**
    *   [ ] A) Choose the principal components.
    *   [ ] B) Compute the covariance matrix.
    *   [ ] C) Project the data.
    *   [ ] D) Calculate the mean of the original data.

    **Answer: B) Compute the covariance matrix.**

    **Explanation:**
    *   Once the data is standardized, the next step is to compute the covariance matrix to understand the relationships between the variables.

43. **How do you decide which principal components to keep?**
    *   [ ] A) By choosing the eigenvectors with the smallest eigenvalues.
    *   [ ] B) By choosing the eigenvectors with the largest eigenvalues.
    *   [ ] C) By choosing the eigenvectors that are closest to the original axes.
    *   [ ] D) By choosing the eigenvectors randomly.

    **Answer: B) By choosing the eigenvectors with the largest eigenvalues.**

    **Explanation:**
    *   Eigenvalues represent the amount of variance captured by their corresponding eigenvectors. To retain the most information, we rank the eigenvectors by their eigenvalues in descending order and keep the top ones.

44. **In the example, the first principal component explained 99.5% of the variance. This indicates that:**
    *   [ ] A) The second principal component is more important than the first.
    *   [ ] B) The two original variables (Math and Physics) are highly correlated.
    *   [ ] C) The two original variables are not correlated.
    *   [ ] D) PCA was not effective.

    **Answer: B) The two original variables (Math and Physics) are highly correlated.**

    **Explanation:**
    *   When a single PC captures almost all the variance, it means the original data points lie very close to a single line (the direction of that PC). This happens when the original variables are highly correlated and essentially measure the same underlying construct.

45. **What is the final step of the PCA process?**
    *   [ ] A) Standardize the data.
    *   [ ] B) Compute the covariance matrix.
    *   [ ] C) Compute the eigenvectors.
    *   [ ] D) Project the original data onto the chosen principal components.

    **Answer: D) Project the original data onto the chosen principal components.**

    **Explanation:**
    *   The final step is to use the chosen eigenvectors to transform the data into the new, lower-dimensional space. This is done by calculating the dot product of the standardized data and the chosen eigenvectors.

46. **If the data is standardized, the variance of each variable is:**
    *   [ ] A) 0
    *   [ ] B) 1
    *   [ ] C) Equal to the mean.
    *   [ ] D) Different for each variable.

    **Answer: B) 1**

    **Explanation:**
    *   Standardization (or Z-score normalization) is the process of rescaling data so that it has a mean of 0 and a standard deviation of 1. Since variance is the square of the standard deviation, the variance is also 1.

47. **The dot product is used in the final step of PCA to:**
    *   [ ] A) Calculate the covariance matrix.
    *   [ ] B) Calculate the eigenvalues.
    *   [ ] C) Project the data onto the new axes.
    *   [ ] D) Standardize the data.

    **Answer: C) Project the data onto the new axes.**

    **Explanation:**
    *   The dot product of a data point's vector with an eigenvector (which is a unit vector) gives the length of the projection of that data point onto the new axis defined by the eigenvector.

48. **If you reduce a 5-dimensional dataset to 2 dimensions using PCA, your final data for each point will be:**
    *   [ ] A) A single number.
    *   [ ] B) A pair of numbers (its coordinate on PC1 and PC2).
    *   [ ] C) A set of 5 numbers.
    *   [ ] D) The original data point.

    **Answer: B) A pair of numbers (its coordinate on PC1 and PC2).**

    **Explanation:**
    *   The dimensionality of the final data is equal to the number of principal components you choose to keep. If you keep 2 PCs, each data point will be represented by two new values.

49. **The sum of the eigenvalues of a covariance matrix is equal to:**
    *   [ ] A) The number of variables.
    *   [ ] B) The total variance in the data.
    *   [ ] C) Zero.
    *   [ ] D) One.

    **Answer: B) The total variance in the data.**

    **Explanation:**
    *   A key property of PCA is that the sum of the eigenvalues is equal to the trace of the covariance matrix, which in turn is equal to the total variance of the data.

50. **To find the percentage of variance explained by a single principal component, you would:**
    *   [ ] A) Divide its eigenvalue by the number of variables.
    *   [ ] B) Divide its eigenvalue by the sum of all eigenvalues.
    *   [ ] C) Multiply its eigenvalue by the number of data points.
    *   [ ] D) Take the square root of its eigenvalue.

    **Answer: B) Divide its eigenvalue by the sum of all eigenvalues.**

    **Explanation:**
    *   The proportion of variance explained by a PC is its corresponding eigenvalue (the variance along that PC) divided by the total variance (the sum of all eigenvalues).
