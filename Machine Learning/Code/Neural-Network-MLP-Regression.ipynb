{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_markdown_new"
      },
      "source": [
        "# MLP for Boston Housing Price Regression\n",
        "This notebook builds a neural network to predict median house values from the Boston Housing dataset. It covers data loading, preprocessing, creating and training multiple MLP architectures, and evaluating their performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_markdown_new"
      },
      "source": [
        "## 1. Importing Libraries\n",
        "First, we import the necessary libraries for data manipulation, numerical operations, model building, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RK9EugjzTUJ2"
      },
      "outputs": [],
      "source": [
        "# Pandas for data loading and manipulation (e.g., reading CSV).\n",
        "import pandas as pd\n",
        "# Random for generating random numbers (used here for the train-test split).\n",
        "import random\n",
        "# NumPy for numerical operations and array handling.\n",
        "import numpy as np\n",
        "# Keras components for building the neural network.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Scikit-learn utilities for model evaluation and preprocessing pipelines.\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_load_markdown_new"
      },
      "source": [
        "## 2. Loading and Preparing the Data\n",
        "We load the Boston Housing dataset, clean it by removing rows with missing values, and then split it into features (X) and the target variable (Y). Finally, we manually split the data into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "51bWw-0CTUJ9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(394, 14)\n"
          ]
        }
      ],
      "source": [
        "# Set a random seed for reproducibility of the train-test split.\n",
        "np.random.seed(2024)\n",
        "\n",
        "# Load the dataset from a file into a pandas DataFrame.\n",
        "dataframe = pd.read_csv(\"HousingData.xls\")\n",
        "\n",
        "# Drop rows with any missing (NaN) values to clean the data.\n",
        "dataframe=dataframe.dropna()\n",
        "\n",
        "# Convert the DataFrame to a NumPy array for use with Keras/Scikit-learn.\n",
        "dataset = dataframe.values\n",
        "print(dataset.shape)\n",
        "\n",
        "# Split the data into input features (X) and the output/target variable (Y).\n",
        "# X contains the first 13 columns (features).\n",
        "X = dataset[:,0:13]\n",
        "# Y contains the 14th column (median house value).\n",
        "Y = dataset[:,13]\n",
        "\n",
        "# ---- Manual Train-Test Split ----\n",
        "num=X.shape[0]   # Total number of samples.\n",
        "frac=0.15        # Fraction of data to be used for the test set (15%).\n",
        "\n",
        "# Randomly select indices for the test set without replacement.\n",
        "test_idx=np.random.choice(range(num), int(num*frac), replace=False)\n",
        "\n",
        "# Create the training set indices from the remaining samples.\n",
        "train_idx=[i for i in range(num) if i not in test_idx]\n",
        "\n",
        "# Create the final training and testing sets based on the selected indices.\n",
        "train_X=X[train_idx]\n",
        "train_Y=Y[train_idx]\n",
        "test_X=X[test_idx]\n",
        "test_Y=Y[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "14iW-wa-SUfq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "394\n",
            "(335, 13) (59, 13)\n"
          ]
        }
      ],
      "source": [
        "# Verify the number of samples and the shapes of the split feature sets.\n",
        "print(num)\n",
        "print(train_X.shape, test_X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kuniw2fhSy5i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(335,) (59,)\n"
          ]
        }
      ],
      "source": [
        "# Verify the shapes of the split target sets.\n",
        "print(train_Y.shape, test_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qgVmFiZ_TUJ_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# Double-check that there are no NaN values left in any of the datasets after cleaning and splitting.\n",
        "print(np.any(np.isnan(train_X)))\n",
        "print(np.any(np.isnan(train_Y)))\n",
        "print(np.any(np.isnan(test_X)))\n",
        "print(np.any(np.isnan(test_Y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model1_markdown_new"
      },
      "source": [
        "## 3. Baseline Model: Shallow Network\n",
        "We'll start with a simple, shallow neural network. It has one input layer that matches the number of features (13) and one output layer with a single neuron to predict the house price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "w9SICDCbTUKA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Program Files\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 365.9705  \n",
            "Epoch 2/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 146.3977\n",
            "Epoch 3/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 115.0660\n",
            "Epoch 4/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 95.9212\n",
            "Epoch 5/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 81.7682\n",
            "Epoch 6/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 72.9959\n",
            "Epoch 7/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 69.5798\n",
            "Epoch 8/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 67.2898\n",
            "Epoch 9/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 64.9570\n",
            "Epoch 10/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 63.5617\n",
            "Epoch 11/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 60.9563\n",
            "Epoch 12/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 60.0850\n",
            "Epoch 13/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 58.5006\n",
            "Epoch 14/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 56.6032\n",
            "Epoch 15/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 55.9070\n",
            "Epoch 16/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 54.9487\n",
            "Epoch 17/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 54.4011\n",
            "Epoch 18/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 53.5879\n",
            "Epoch 19/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 52.9315\n",
            "Epoch 20/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 53.4699\n",
            "Epoch 21/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 51.9986\n",
            "Epoch 22/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 51.1588\n",
            "Epoch 23/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 51.1633\n",
            "Epoch 24/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 50.2631\n",
            "Epoch 25/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 49.7697\n",
            "Epoch 26/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 49.1589\n",
            "Epoch 27/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 48.7180\n",
            "Epoch 28/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 47.1373\n",
            "Epoch 29/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 47.2314\n",
            "Epoch 30/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 46.6344\n",
            "Epoch 31/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 46.3645\n",
            "Epoch 32/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 47.1197\n",
            "Epoch 33/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 44.8920\n",
            "Epoch 34/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 44.5840\n",
            "Epoch 35/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 43.9804\n",
            "Epoch 36/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 43.6539\n",
            "Epoch 37/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 43.7224\n",
            "Epoch 38/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 42.3334\n",
            "Epoch 39/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 42.5639\n",
            "Epoch 40/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 42.5394\n",
            "Epoch 41/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 41.0129\n",
            "Epoch 42/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 42.4642\n",
            "Epoch 43/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 40.6109\n",
            "Epoch 44/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 39.7983\n",
            "Epoch 45/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 39.6330\n",
            "Epoch 46/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 39.4913\n",
            "Epoch 47/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 38.3097\n",
            "Epoch 48/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 38.1262\n",
            "Epoch 49/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 38.8989\n",
            "Epoch 50/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 37.9190\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x128540e39d0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the Keras model using the Sequential API.\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer: 13 neurons (one for each feature), with a ReLU activation function.\n",
        "# `kernel_initializer='normal'` sets the initial weights from a normal distribution.\n",
        "model.add(Dense(13, input_shape=(13,), kernel_initializer='normal', activation='relu'))\n",
        "\n",
        "# Output layer: 1 neuron for the single continuous output value (house price).\n",
        "# A linear activation function is used by default, which is appropriate for regression.\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile the model.\n",
        "# `loss='mean_squared_error'` is a standard loss function for regression problems.\n",
        "# `optimizer='adam'` is an efficient and popular optimization algorithm.\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Train the model on the training data for 50 epochs.\n",
        "model.fit(train_X, train_Y, epochs=50, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h1zQmglKTUKA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.5229\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained model's performance (mean squared error) on the unseen test data.\n",
        "loss=model.evaluate(test_X, test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "V2oZXkMDUhZR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "[[26.105427]] 23.8\n"
          ]
        }
      ],
      "source": [
        "# Use the model to predict the price for the first sample in the test set.\n",
        "# The input needs to be reshaped to (1, 13) to represent a single sample.\n",
        "y=model.predict(test_X[0].reshape(1,13))\n",
        "\n",
        "# Print the predicted value and the actual value to compare.\n",
        "print(y, test_Y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model2_markdown_new"
      },
      "source": [
        "## 4. Deeper Network Architecture\n",
        "Now, let's see if a deeper network performs better. We add an extra hidden layer with 6 neurons. This increases the model's capacity to learn more complex relationships in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ou9UnKxZTUKB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 560.5049 \n",
            "Epoch 2/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 372.6039\n",
            "Epoch 3/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 136.2320\n",
            "Epoch 4/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 109.8841\n",
            "Epoch 5/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 89.9526\n",
            "Epoch 6/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 76.7813\n",
            "Epoch 7/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 68.9657\n",
            "Epoch 8/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 62.5883\n",
            "Epoch 9/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 59.2228\n",
            "Epoch 10/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 57.9250\n",
            "Epoch 11/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 57.6146\n",
            "Epoch 12/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 55.5188\n",
            "Epoch 13/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 55.2684\n",
            "Epoch 14/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 54.5823\n",
            "Epoch 15/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 53.6453\n",
            "Epoch 16/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 54.1265\n",
            "Epoch 17/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 53.7564\n",
            "Epoch 18/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 52.8840\n",
            "Epoch 19/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 52.6612\n",
            "Epoch 20/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 51.4065\n",
            "Epoch 21/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 51.8107\n",
            "Epoch 22/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 52.2427\n",
            "Epoch 23/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 50.2188\n",
            "Epoch 24/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 49.9511\n",
            "Epoch 25/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 49.6274\n",
            "Epoch 26/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 48.8161\n",
            "Epoch 27/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 48.6768\n",
            "Epoch 28/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 47.6118\n",
            "Epoch 29/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 47.2081\n",
            "Epoch 30/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47.2677 \n",
            "Epoch 31/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 46.7358\n",
            "Epoch 32/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 46.2510\n",
            "Epoch 33/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 44.9662\n",
            "Epoch 34/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 46.8498\n",
            "Epoch 35/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 44.8704\n",
            "Epoch 36/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 44.1518\n",
            "Epoch 37/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 43.3296\n",
            "Epoch 38/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 42.3572\n",
            "Epoch 39/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 42.8848\n",
            "Epoch 40/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 41.4519\n",
            "Epoch 41/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 41.1499\n",
            "Epoch 42/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 40.2581\n",
            "Epoch 43/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 39.1581\n",
            "Epoch 44/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 39.3249\n",
            "Epoch 45/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 39.4689\n",
            "Epoch 46/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 38.4458\n",
            "Epoch 47/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 37.4580\n",
            "Epoch 48/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 36.9894\n",
            "Epoch 49/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 36.8586\n",
            "Epoch 50/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35.5566 \n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 28.5517\n"
          ]
        }
      ],
      "source": [
        "# Define a deeper sequential model.\n",
        "model = Sequential()\n",
        "# Input layer (same as before).\n",
        "model.add(Dense(13, input_shape=(13,), kernel_initializer='normal', activation='relu'))\n",
        "# New hidden layer with 6 neurons.\n",
        "model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "# Output layer (same as before).\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile and train the model.\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(train_X, train_Y, epochs=50, batch_size=10)\n",
        "\n",
        "# Evaluate the deeper model on the test data.\n",
        "loss=model.evaluate(test_X, test_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model3_markdown_new"
      },
      "source": [
        "## 5. Wider Network Architecture\n",
        "Let's try a wider network by increasing the number of neurons in the first hidden layer to 20. This also increases the model's capacity but in a different way than making it deeper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dvvfLtQBTUKB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 303.5621\n",
            "Epoch 2/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 150.6651\n",
            "Epoch 3/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 109.9594\n",
            "Epoch 4/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 83.2747\n",
            "Epoch 5/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 74.1323\n",
            "Epoch 6/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 72.9651\n",
            "Epoch 7/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 67.9977\n",
            "Epoch 8/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 67.1450\n",
            "Epoch 9/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 67.5054\n",
            "Epoch 10/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 69.1134\n",
            "Epoch 11/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 65.2914\n",
            "Epoch 12/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 63.5001\n",
            "Epoch 13/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 62.2423\n",
            "Epoch 14/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 62.5528\n",
            "Epoch 15/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 61.8602\n",
            "Epoch 16/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 60.7648\n",
            "Epoch 17/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 59.3887\n",
            "Epoch 18/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 60.2245\n",
            "Epoch 19/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 59.0702\n",
            "Epoch 20/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 58.5403\n",
            "Epoch 21/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 58.2648\n",
            "Epoch 22/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 59.4264\n",
            "Epoch 23/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 56.9563\n",
            "Epoch 24/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 60.0966\n",
            "Epoch 25/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 55.6909\n",
            "Epoch 26/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 55.1179\n",
            "Epoch 27/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 54.6441\n",
            "Epoch 28/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 56.7396\n",
            "Epoch 29/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 55.3531\n",
            "Epoch 30/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 53.1429\n",
            "Epoch 31/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 52.6077\n",
            "Epoch 32/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 53.2151\n",
            "Epoch 33/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 52.7882\n",
            "Epoch 34/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 51.6736\n",
            "Epoch 35/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 51.7582\n",
            "Epoch 36/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 50.4525\n",
            "Epoch 37/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 52.1511\n",
            "Epoch 38/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 49.6508\n",
            "Epoch 39/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 50.9069\n",
            "Epoch 40/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 49.1157\n",
            "Epoch 41/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 49.1957\n",
            "Epoch 42/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 48.7621\n",
            "Epoch 43/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 47.4368\n",
            "Epoch 44/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 46.7906\n",
            "Epoch 45/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 47.3247\n",
            "Epoch 46/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 47.3544\n",
            "Epoch 47/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 46.7114\n",
            "Epoch 48/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 45.7148\n",
            "Epoch 49/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 45.2087\n",
            "Epoch 50/50\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 44.5518\n"
          ]
        }
      ],
      "source": [
        "# Define a wider sequential model.\n",
        "model = Sequential()\n",
        "# Wider hidden layer with 20 neurons.\n",
        "model.add(Dense(20, input_shape=(13,), kernel_initializer='normal', activation='relu'))\n",
        "# Output layer.\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile and train the model, saving the history.\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history=model.fit(train_X, train_Y, epochs=50, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tOmKl4C_wr0G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 37.2776\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the wider model.\n",
        "loss=model.evaluate(test_X, test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qeMNK9u0ooBh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 37.2776\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "[0.08352394]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate and make a prediction with the final model.\n",
        "loss_val = model.evaluate(test_X, test_Y)\n",
        "predictions = model.predict(test_X)\n",
        "\n",
        "# Calculate the difference between the predicted and actual value for a specific sample.\n",
        "difference = predictions[12] - test_Y[12]\n",
        "print(difference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viz_markdown_new"
      },
      "source": [
        "## 6. Visualizing Training Loss\n",
        "We can plot the training loss over epochs to visualize how the model's error decreased during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_kUuD7aelLIu"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import plotting libraries.\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a pandas DataFrame from the training history.\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "# Add a grid for better readability.\n",
        "plt.grid(True)\n",
        "# Display the plot.\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf29",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
