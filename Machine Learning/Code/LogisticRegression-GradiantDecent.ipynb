{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "This notebook implements a **Logistic Regression** model for binary classification from scratch using Python and NumPy. The core of the model is trained using **gradient descent**.\n",
    "\n",
    "We will train our custom model on the PIMA Indians Diabetes Dataset and then compare its performance against the highly optimized Logistic Regression implementation from the `scikit-learn` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Core Model Functions\n",
    "\n",
    "Here we define the building blocks of our model:\n",
    "- **`sigmoid_function`**: The activation function that maps any real value into a probability between 0 and 1.\n",
    "- **`compute_gradients`**: Calculates the gradients (derivatives) of the loss function, which are needed to update the model's parameters.\n",
    "- **`predict`**: Uses the trained model (weights and bias) to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(x):\n",
    "    \"\"\"Numerically stable implementation of the sigmoid function.\"\"\"\n",
    "    if x >= 0:\n",
    "      z = np.exp(-x)\n",
    "      return 1 / (1 + z)\n",
    "    else:\n",
    "      z = np.exp(x)\n",
    "      return z / (1 + z)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Element-wise wrapper for the sigmoid function.\"\"\"\n",
    "    return np.array([sigmoid_function(value) for value in x])\n",
    "\n",
    "def compute_gradients(x, y_true, y_pred):\n",
    "    \"\"\"Computes the gradients of the binary cross-entropy loss function.\"\"\"\n",
    "    difference = y_pred - y_true\n",
    "    gradient_b = np.mean(difference)\n",
    "    gradients_w = np.matmul(x.transpose(), difference) / len(y_true)\n",
    "    return gradients_w, gradient_b\n",
    "\n",
    "def predict(x, weights, bias):\n",
    "    \"\"\"Uses the learned weights and bias to make predictions.\"\"\"\n",
    "    x_dot_weights = np.matmul(weights, x.transpose()) + bias\n",
    "    probabilities = sigmoid(x_dot_weights)\n",
    "    return [1 if p > 0.5 else 0 for p in probabilities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training with Gradient Descent\n",
    "\n",
    "The `train` function implements the gradient descent algorithm. It iteratively adjusts the model's **weights** and **bias** to minimize the prediction error over a number of **epochs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, epochs, learning_rate):\n",
    "    \"\"\"Trains the logistic regression model using gradient descent.\"\"\"\n",
    "    weights = np.zeros(x.shape[1])\n",
    "    bias = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        # 1. Get predicted probabilities\n",
    "        x_dot_weights = np.matmul(weights, x.transpose()) + bias\n",
    "        pred = sigmoid(x_dot_weights)\n",
    "        \n",
    "        # 2. Compute gradients\n",
    "        error_w, error_b = compute_gradients(x, y, pred)\n",
    "        \n",
    "        # 3. Update weights and bias\n",
    "        weights -= learning_rate * error_w\n",
    "        bias -= learning_rate * error_b\n",
    "        \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Splitting\n",
    "\n",
    "We load the diabetes dataset, prepare the feature matrix (`x`) and target vector (`y`), and then split them into training and testing sets. This ensures we can evaluate our model on data it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'diabetes.csv' loaded successfully!\n",
      "Data split complete:\n",
      "x_train shape: (614, 2)\n",
      "x_test shape:  (154, 2)\n"
     ]
    }
   ],
   "source": [
    "# Set the path to your CSV file.\n",
    "# For best results, place 'diabetes.csv' in the same folder as this notebook.\n",
    "path = r\"diabetes.csv\"\n",
    "\n",
    "try:\n",
    "    file = pd.read_csv(path)\n",
    "    print(f\"File '{path}' loaded successfully!\")\n",
    "    \n",
    "    # Prepare the data\n",
    "    y = np.array(file[\"Outcome\"])\n",
    "    x = np.array(file[[\"Glucose\", \"BMI\"]])\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    # A 80/20 split is common practice (train_size=0.8)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)\n",
    "    print(f\"Data split complete:\")\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"x_test shape:  {x_test.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at '{path}'\")\n",
    "    print(\"Please make sure the 'diabetes.csv' file is in the same directory as the notebook, or update the 'path' variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Our Custom Model\n",
    "\n",
    "Now we train our custom model using the training data and then evaluate its performance by making predictions on the test set and calculating the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Custom Logistic Regression Model ---\n",
      "Learned Weights: [ 0.02700935 -0.06431908]\n",
      "Learned Bias: -0.08658905905005242\n",
      "Our model accuracy: 0.4026\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "epochs = 2000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Train the model and get the learned parameters\n",
    "weights, bias = train(x_train, y_train, epochs, learning_rate)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = predict(x_test, weights, bias)\n",
    "\n",
    "print(\"--- Custom Logistic Regression Model ---\")\n",
    "print(f\"Learned Weights: {weights}\")\n",
    "print(f\"Learned Bias: {bias}\")\n",
    "print(f\"Our model accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison with Scikit-learn\n",
    "\n",
    "Finally, we train a `scikit-learn` `LogisticRegression` model on the exact same data to see how our implementation compares to a standard, highly optimized library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scikit-learn Logistic Regression Model ---\n",
      "Sklearn model accuracy: 0.7662\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the sklearn model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "sklearn_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "sklearn_accuracy = accuracy_score(y_test, sklearn_pred)\n",
    "\n",
    "print(\"--- Scikit-learn Logistic Regression Model ---\")\n",
    "print(f\"Sklearn model accuracy: {sklearn_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
