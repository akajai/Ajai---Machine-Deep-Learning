{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Classifier for Diabetes Prediction\n",
    "\n",
    "This notebook demonstrates how to build and evaluate a Stacking Classifier using the PIMA Indians Diabetes Dataset. Stacking is an ensemble learning technique that uses the predictions of multiple models (called base learners) as input for a final model (called a meta-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and reading CSV files\n",
    "import numpy as np   # For numerical operations (though not explicitly used here, it's good practice)\n",
    "\n",
    "# Import train_test_split to divide the dataset into training and testing subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the individual machine learning models that will be used as base learners\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron (a simple neural network)\n",
    "\n",
    "# Import the StackingClassifier, which allows us to combine the base learners\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Import accuracy_score to evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare the Data\n",
    "\n",
    "We'll start by loading the dataset from a CSV file and preparing it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "\n",
      "Training data shape: (537, 8)\n",
      "Testing data shape: (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the 'diabetes.csv' file into a pandas DataFrame\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame to get a quick overview of the data\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Separate the features (independent variables) from the target (dependent variable)\n",
    "# 'X' contains all columns except for 'Outcome'\n",
    "X = df.drop('Outcome', axis='columns') \n",
    "# 'y' contains only the 'Outcome' column, which is what we want to predict\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the entire dataset into training and testing sets\n",
    "# test_size=0.3 means 30% of the data will be used for testing, and 70% for training\n",
    "# random_state=42 ensures that the split is the same every time the code is run, for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Base Learners and Meta-Model\n",
    "\n",
    "Stacking involves two levels of models:\n",
    "1.  **Base Learners**: A set of diverse models that are trained on the original dataset.\n",
    "2.  **Meta-Model**: A final model that is trained on the *predictions* made by the base learners.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of base learners (level-0 models)\n",
    "# Each model is a tuple containing a name and the model instance\n",
    "base_learners = [\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('ann', MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)),\n",
    "    ('svm', SVC(kernel='linear', probability=True, random_state=42)), # probability=True is often needed for meta-learners\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('nb', GaussianNB())\n",
    "]\n",
    "\n",
    "# Define the meta-model (level-1 model)\n",
    "# This model will learn from the outputs of the base learners\n",
    "meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and Train the Stacking Ensemble\n",
    "\n",
    "Now we'll use Scikit-Learn's `StackingClassifier` to combine our base learners and the meta-model. The `fit` method handles the entire training process automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Stacking Classifier...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Stacking Classifier\n",
    "# `estimators`: The list of base learners\n",
    "# `final_estimator`: The meta-model\n",
    "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model, cv=5) # cv=5 means cross-validation is used to generate predictions for the meta-model\n",
    "\n",
    "# Train the stacking model on the training data\n",
    "# This process trains all base learners and then trains the meta-model on their predictions\n",
    "print(\"Training the Stacking Classifier...\")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Model's Performance\n",
    "\n",
    "We'll use the trained stacking model to make predictions on the test set and then calculate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the Stacking Classifier: 75.32%\n"
     ]
    }
   ],
   "source": [
    "# Use the trained stacking model to make predictions on the test set\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy by comparing the predicted values (y_pred) with the actual values (y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the final accuracy, formatted as a percentage with two decimal places\n",
    "print(f'\\nAccuracy of the Stacking Classifier: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
